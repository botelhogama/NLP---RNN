{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "        In the contemporary research landscape, deep learning has emerged as a pivotal tool for various applications, including text classification. This study aims to construct a deep learning architecture, employing Bidirectional Recurrent Neural Networks (BRNNs), Gated Recurrent Units (GRUs), and Long Short-Term Memory (LSTM) networks, to effectively classify textual data. The dataset, integral to this research, encompasses texts annotated with binary labels, either 0 or 1.\n",
    "\n",
    "        These labels have distinct connotations in the context of disasters. Specifically, texts labeled with 0 signify the absence of any indicators pointing to ongoing disasters, whereas those marked with 1 serve as an explicit confirmation of the occurrence of incidents. By leveraging the power of BRNNs, GRUs, and LSTMs, this study seeks to develop a robust text classification model that can accurately discern the presence or absence of emergency incidents from the analyzed textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import string\n",
    "\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import digits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, Dropout, Conv1D, MaxPooling1D, Flatten, LeakyReLU, Bidirectional, GlobalMaxPool1D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers, regularizers, optimizers, metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNGRU as gru\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 600)\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is equal to (7613, 5)\n",
      "there is 0 null values in target equal to 1\n",
      "there is 0 null values in target equal to 0\n"
     ]
    }
   ],
   "source": [
    "train[train['target']==1]['target'].isnull().sum()\n",
    "train[train['target']==0]['target'].isnull().sum()\n",
    "print('train shape is equal to', (train.shape[0],  train.shape [1]))\n",
    "print('there is', train[train['target']==1]['target'].isnull().sum() , 'null values in target equal to 1' )\n",
    "print('there is', train[train['target']==0]['target'].isnull().sum() , 'null values in target equal to 0' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0         1   \n",
       "1         4   \n",
       "2         5   \n",
       "3         6   \n",
       "4         7   \n",
       "...     ...   \n",
       "7608  10869   \n",
       "7609  10870   \n",
       "7610  10871   \n",
       "7611  10872   \n",
       "7612  10873   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "0                                                                         Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                        Forest fire near La Ronge Sask. Canada   \n",
       "2         All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                             13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                                      Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "...                                                                                                                                         ...   \n",
       "7608                                                        Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5   \n",
       "7609              @aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.   \n",
       "7610                                                                          M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ   \n",
       "7611  Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.   \n",
       "7612                                             The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d   \n",
       "\n",
       "      target  length  \n",
       "0          1      69  \n",
       "1          1      38  \n",
       "2          1     133  \n",
       "3          1      65  \n",
       "4          1      88  \n",
       "...      ...     ...  \n",
       "7608       1      83  \n",
       "7609       1     125  \n",
       "7610       1      65  \n",
       "7611       1     137  \n",
       "7612       1      94  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['length'] = train['text'].apply(len)\n",
    "train = train.drop(['keyword', 'location'], axis = 1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4342\n",
      "1    3271\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "plt.hist(train.target ,density = 0, edgecolor='k', color ='blue', alpha = 0.6)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.title(\"The Distribution of Category\")\n",
    "plt.show()\n",
    "print(train.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['length'] ,density = 0, edgecolor='k',  color ='blue', alpha = 0.6)\n",
    "plt.title(\"Text Length Histogram\")\n",
    "plt.grid(axis='y', alpha=0.75);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "        The tokenize function presented herein is devised to process and preprocess textual data, facilitating its subsequent analysis. By incorporating various optional parameters, the function offers flexibility in addressing specific requirements. These parameters include the choice of text processing mode ('lemma', 'stem', or 'word'), the decision to eliminate stop words, and the option to convert all tokens to lowercase.\n",
    "        Based on the chosen mode, the function conducts stemming, word filtering, or lemmatization. For each mode, the function returns a modified version of the text, comprising either stemmed words, filtered words, or lemmatized words. In the case where stop word removal is not desired, the function processes the text accordingly and returns the appropriately transformed output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text , mode = 'lemma', stop_words = 'yes', lower_case = 'yes'):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "\n",
    "    # Remove Twitter handles\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "\n",
    "    # Handle contractions\n",
    "    contractions = {\"'s \": \" is\", \"'re\": \" are\", \"n't \": \" not\", \"'ve \": \" have\", \"'ll\": \" will\", \"'d \": \" would\", \"'m \": \" am\", \"'em \": \" them\"}\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = re.sub(contraction, expansion, text)\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # Remove punctuation and digits\n",
    "    text = re.sub(r\"[{}]\".format(string.punctuation + string.digits), \" \", text)\n",
    "    \n",
    "    if stop_words == 'yes':\n",
    "        remove_digits = str.maketrans('', '', digits)\n",
    "        lemm = stem.WordNetLemmatizer()\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        tokens = [word for word in nltk.word_tokenize(text) if len(word)>2]        #get all words with len>3 from the text as a token\n",
    "        \n",
    "        if lower_case == 'yes':\n",
    "            tokens = map(str.lower , tokens)                                           #apply lower case letters to all tokens \n",
    "        if mode == 'stem':\n",
    "            stems = [stemmer.stem(item) for item in tokens if (item not in stop_words)]\n",
    "            return \" \".join(stems)\n",
    "        elif mode == 'word':\n",
    "            words = [word for word in tokens if (item not in stop_words)]\n",
    "            return \" \".join(words)\n",
    "        elif mode == 'lemma':\n",
    "            lemma = [lemm.lemmatize(item.translate(remove_digits)) for item in tokens if (item not in stop_words) ]\n",
    "            return \" \".join(lemma)\n",
    "\n",
    "    elif stop_words == 'no':\n",
    "        remove_digits = str.maketrans('', '', digits)\n",
    "        tokens = [word for word in nltk.word_tokenize(text) if len(word)>2]         #get all words with len>3 from the text as a token\n",
    "        if lower_case == 'yes':\n",
    "            tokens = map(str.lower , tokens)                                            #apply lower case letters to all tokens \n",
    "        if mode == 'stem':\n",
    "            stems = [stemmer.stem(item) for item in tokens]\n",
    "            return \" \".join(stems)\n",
    "        elif mode == 'word':\n",
    "            words = [word for word in tokens]\n",
    "            return \" \".join(words)\n",
    "        elif mode == 'lemma':\n",
    "            lemma = [lemm.lemmatize(item.translate(remove_digits)) for item in tokens]\n",
    "            return \" \".join(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>deed reason earthquake may allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>forest fire near ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>resident asked shelter place notified officer evacuation shelter place order expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>people receive wildfire evacuation order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pours school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>two giant crane holding bridge collapse nearby home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>control wild fire california even northern part state troubling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>utc volcano hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>police investigating bike collided car little portugal bike rider suffered serious non life threatening injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>latest home razed northern california wildfire abc news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0         1   \n",
       "1         4   \n",
       "2         5   \n",
       "3         6   \n",
       "4         7   \n",
       "...     ...   \n",
       "7608  10869   \n",
       "7609  10870   \n",
       "7610  10871   \n",
       "7611  10872   \n",
       "7612  10873   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "0                                                                         Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                        Forest fire near La Ronge Sask. Canada   \n",
       "2         All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                             13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                                      Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "...                                                                                                                                         ...   \n",
       "7608                                                        Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5   \n",
       "7609              @aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.   \n",
       "7610                                                                          M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ   \n",
       "7611  Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.   \n",
       "7612                                             The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d   \n",
       "\n",
       "      target  length  \\\n",
       "0          1      69   \n",
       "1          1      38   \n",
       "2          1     133   \n",
       "3          1      65   \n",
       "4          1      88   \n",
       "...      ...     ...   \n",
       "7608       1      83   \n",
       "7609       1     125   \n",
       "7610       1      65   \n",
       "7611       1     137   \n",
       "7612       1      94   \n",
       "\n",
       "                                                                                                               token  \n",
       "0                                                                           deed reason earthquake may allah forgive  \n",
       "1                                                                                 forest fire near ronge sask canada  \n",
       "2                              resident asked shelter place notified officer evacuation shelter place order expected  \n",
       "3                                                                people receive wildfire evacuation order california  \n",
       "4                                                             got sent photo ruby alaska smoke wildfire pours school  \n",
       "...                                                                                                              ...  \n",
       "7608                                                             two giant crane holding bridge collapse nearby home  \n",
       "7609                                                 control wild fire california even northern part state troubling  \n",
       "7610                                                                                              utc volcano hawaii  \n",
       "7611  police investigating bike collided car little portugal bike rider suffered serious non life threatening injury  \n",
       "7612                                                         latest home razed northern california wildfire abc news  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply preprocessing functions on the train and test datasets\n",
    "train['token'] = train['text'].apply(tokenize)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amp             330\n",
       "like            290\n",
       "fire            272\n",
       "get             210\n",
       "one             157\n",
       "               ... \n",
       "clipblack         1\n",
       "destroyedsay      1\n",
       "silas             1\n",
       "sliced            1\n",
       "injurylatest      1\n",
       "Length: 17771, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.Series(''.join(train.token).split())\n",
    "word_count = words.value_counts()\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>153</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>134</td>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>134</td>\n",
       "      <td>emergency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>125</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>125</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>121</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>121</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>121</td>\n",
       "      <td>building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>120</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>120</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>116</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>116</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>114</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>111</td>\n",
       "      <td>police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>101</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99</td>\n",
       "      <td>bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>99</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>98</td>\n",
       "      <td>crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>98</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>95</td>\n",
       "      <td>nuclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>95</td>\n",
       "      <td>storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>94</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>94</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>93</td>\n",
       "      <td>burning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>90</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>89</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>89</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>88</td>\n",
       "      <td>california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>88</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>88</td>\n",
       "      <td>killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>87</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>86</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>86</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>85</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>84</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>84</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>82</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>82</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>80</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>79</td>\n",
       "      <td>could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>78</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>78</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>77</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>76</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count        word\n",
       "1     330         amp\n",
       "2     290        like\n",
       "3     272        fire\n",
       "4     210         get\n",
       "5     157         one\n",
       "6     153      people\n",
       "7     134        body\n",
       "8     134   emergency\n",
       "9     125    disaster\n",
       "10    125        time\n",
       "11    121       video\n",
       "12    121       would\n",
       "13    121    building\n",
       "14    120        home\n",
       "15    120         new\n",
       "16    116        year\n",
       "17    116         day\n",
       "18    114        news\n",
       "19    111      police\n",
       "20    101        life\n",
       "21    100         say\n",
       "22     99        bomb\n",
       "23     99         car\n",
       "24     98       crash\n",
       "25     98       train\n",
       "26     95     nuclear\n",
       "27     95       storm\n",
       "28     94         war\n",
       "29     94       world\n",
       "30     93     burning\n",
       "31     90        back\n",
       "32     89         got\n",
       "33     89     suicide\n",
       "34     88  california\n",
       "35     88       still\n",
       "36     88      killed\n",
       "37     87       first\n",
       "38     86         man\n",
       "39     86      attack\n",
       "40     85       flood\n",
       "41     84        make\n",
       "42     84         two\n",
       "43     82        look\n",
       "44     82         old\n",
       "45     80         may\n",
       "46     79       could\n",
       "47     78       death\n",
       "48     78      family\n",
       "49     77        take\n",
       "50     76         see"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = pd.DataFrame(data=word_count, columns = ['count'])\n",
    "word_count['word'] = word_count.index\n",
    "word_count.index = range(1,word_count.shape[0]+1)\n",
    "word_count[:50]\n",
    "#sns.barplot(data=word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sns.countplot(data = word_count, x=word_count['word'])\\nplt.show()\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sns.countplot(data = word_count, x=word_count['word'])\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"oov\", num_words=18000)\n",
    "tokenizer.fit_on_texts(train[\"text\"])\n",
    "len(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models\n",
    "\n",
    "        In the pursuit of optimal model performance, various architectural parameters can be explored and fine-tuned to construct a robust architecture capable of achieving a high F1 score. The primary objective is to identify the best-performing model through comparative analysis and subsequently utilize this model for evaluating test scores.\n",
    "\n",
    "        One crucial step in this process is the tokenization of the data. It is worth noting that state-of-the-art natural language processing (NLP) models currently tend to retain stopwords in the text, as these words contribute valuable contextual information. However, in order to simplify the analysis and streamline the process, stopwords will be removed in this particular study. This decision may impact the overall model performance and is a trade-off that should be carefully considered in the context of the specific problem being addressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(train[\"text\"], train[\"target\"], test_size=0.15)\n",
    "Xtrain=tokenizer.texts_to_sequences(Xtrain)\n",
    "Xtrain = pad_sequences(sequences=Xtrain, maxlen=50)\n",
    "\n",
    "Xval=tokenizer.texts_to_sequences(Xval)\n",
    "Xval = pad_sequences(sequences=Xval, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.f1_scores = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.X_val)\n",
    "        y_pred = (y_pred > 0.5).astype(int)\n",
    "        f1 = f1_score(self.y_val, y_pred)\n",
    "        logs['val_f1_score'] = f1\n",
    "        self.f1_scores.append(f1)\n",
    "        print(f' - val_f1_score: {f1:.4f}')\n",
    "        \n",
    "    def plot_f1_scores(self):\n",
    "        plt.plot(self.f1_scores)\n",
    "        plt.grid(True, color = 'gray')\n",
    "        plt.title('F1 Score vs Epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.show()\n",
    "        \n",
    "def evaluate_model(model ,lr, epoch):\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\", 'AUC'])\n",
    "    f1_score_callback = F1ScoreCallback(Xval, yval)\n",
    "    modelfit = model.fit(Xtrain, ytrain, \n",
    "                         validation_data=(Xval, yval),\n",
    "                         epochs=epoch,\n",
    "                         batch_size=128, \n",
    "                         callbacks=[f1_score_callback])\n",
    "    model.summary()\n",
    "    fig = plt.figure(figsize=(8,10))\n",
    "    # plot training and validation accuracy\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(modelfit.history['accuracy'], label=\"train accuracy\" )\n",
    "    plt.plot(modelfit.history['val_accuracy'], label=\"validation accuracy\")\n",
    "    plt.grid(True, color = 'gray')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    # plot F1 score\n",
    "    plt.subplot(2, 1, 2)\n",
    "    f1_score_callback.plot_f1_scores()\n",
    "    \n",
    "    \n",
    "    # adjust spacing between subplots\n",
    "    plt.subplots_adjust(hspace=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "        This function builds a Keras model for a bidirectional GRU neural network for text classification. The model takes as input sequences of length 50 and applies an embedding layer with dropout regularization to reduce overfitting. The output of the embedding layer is then fed into three bidirectional GRU layers with varying sizes (128, 64, and 32) and dropout regularization to extract relevant features from the input sequence. Finally, a dense layer with sigmoid activation function is applied to produce a binary output indicating the classification result.\n",
    "\n",
    "    The function accepts four hyperparameters:\n",
    "\n",
    "  - embdim: dimensionality of the embedding layer output.\n",
    "  - emb_dropout: dropout rate applied to the embedding layer.\n",
    "  - dropout_rate: dropout rate applied to the GRU layers.\n",
    "  - reg: regularization strength applied to the GRU kernel and activity weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(embdim=512, emb_dropout=0.2, dropout_rate=0.3, reg=0.001):\n",
    "    i = layers.Input(shape=(50,))\n",
    "    x = layers.Embedding(15000,embdim)(i)\n",
    "    x = layers.Dropout(emb_dropout)(x)\n",
    "    x = layers.Bidirectional(gru(128,\n",
    "                                 return_sequences=True,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l2(reg)))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Bidirectional(gru(64,\n",
    "                                 return_sequences=True,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l2(reg)))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Bidirectional(gru(32,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(reg),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l2(reg)))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs=i, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 512)           7680000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 512)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 50, 256)          493056    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 50, 128)          123648    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               31104     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,327,873\n",
      "Trainable params: 8,327,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNNV2' used by {{node model/bidirectional/forward_cu_dnngru/CudnnRNNV2}} with these attrs: [dropout=0, seed=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"gru\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  device='GPU'; T in [DT_HALF]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_DOUBLE]\n\n\t [[model/bidirectional/forward_cu_dnngru/CudnnRNNV2]] [Op:__inference_train_function_5751]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m build_model1()\n\u001b[0;32m      2\u001b[0m model1\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 28\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, lr, epoch)\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     27\u001b[0m f1_score_callback \u001b[38;5;241m=\u001b[39m F1ScoreCallback(Xval, yval)\n\u001b[1;32m---> 28\u001b[0m modelfit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mf1_score_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     34\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNNV2' used by {{node model/bidirectional/forward_cu_dnngru/CudnnRNNV2}} with these attrs: [dropout=0, seed=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"gru\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  device='GPU'; T in [DT_HALF]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_DOUBLE]\n\n\t [[model/bidirectional/forward_cu_dnngru/CudnnRNNV2]] [Op:__inference_train_function_5751]"
     ]
    }
   ],
   "source": [
    "model1 = build_model1()\n",
    "model1.summary()\n",
    "evaluate_model(model1, 0.001, epoch = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "           This model looks similar to build_model1 with lower vocabulary size (5000 instead of 15000) and slightly smaller embedding dimension (512 instead of 512). It also has more dropout with a lower rate (0.1 instead of 0.25) and lower L1 regularization (0.0001 instead of 0.001). The overall structure of the model is still the same with 4 bidirectional GRU layers and a dense output layer with sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(embdim=512, emb_dropout=0.1, dropout_rate=0.1, reg=0.0001):\n",
    "    i = layers.Input(shape=(50,))\n",
    "    x = layers.Embedding(5000,embdim)(i)\n",
    "    x = layers.Dropout(emb_dropout)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(gru(256,\n",
    "                                 return_sequences=True,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(reg),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l1(reg)))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(gru(128,\n",
    "                                 return_sequences=True,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(reg),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l1(reg)))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(gru(64,\n",
    "                                 return_sequences=True,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(reg),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l1(reg)))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Bidirectional(gru(64,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(reg),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l1(reg)))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs=i, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_model2()\n",
    "evaluate_model(model2, 0.0001, epoch = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3\n",
    "    \n",
    "        The architecture of model 2 was replicated, with the exception of a small adjustment made to the learning rate. Specifically, the optimization algorithm utilized a smaller learning rate compared to the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = build_model1()\n",
    "evaluate_model(model1, 0.00001, epoch = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4\n",
    "\n",
    "        Model 4 is a Convolutional Neural Network (CNN) for binary classification of emergency vs non-emergency tweets. The model is composed of an embedding layer, followed by two sets of convolutional and pooling layers, a flatten layer, and two fully connected layers. The embedding layer uses pre-trained GloVe embeddings to convert the text data into a dense vector representation. The convolutional and pooling layers are designed to capture local patterns and features in the text data, while reducing the dimensionality of the data. \n",
    "        The flatten layer is used to transform the output from the convolutional layers into a 1-dimensional vector, which is fed into the fully connected layers for classification. The LeakyReLU activation function is used in the convolutional and dense layers, which allows for faster convergence and better performance than traditional activation functions. Dropout regularization is also used to prevent overfitting. The model is trained using binary cross-entropy loss and optimized using the RMSprop optimizer with a learning rate of 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('glove.twitter.27B.200d.txt', encoding=\"utf8\")\n",
    "embeddings_index = dict()\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "embedding_matrix = np.zeros((15000, 200))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > 1500 - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model4(embdim=200, emb_dropout=0.2, dropout_rate=0.25, reg=0.001):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape = (50,)))\n",
    "    model.add(Embedding(15000,embdim, weights = [embedding_matrix]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(16, 3, padding = 'valid', activation = 'LeakyReLU'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(16, 3, padding = 'valid', activation = 'LeakyReLU'))\n",
    "    model.add(MaxPooling1D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation = 'LeakyReLU'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = build_model4()\n",
    "evaluate_model(model4, 0.001, epoch = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5\n",
    "\n",
    "        Model 5 is a deep learning architecture that employs a combination of 1D convolutional layers and a Bidirectional Gated Recurrent Unit (BiGRU) layer for processing input sequences. The model is designed for binary classification tasks.\n",
    "        The input sequence is passed through an Embedding layer with pre-trained weights from the embedding_matrix and a dropout layer for regularization. The model then processes the output through two successive 1D convolutional layers, each followed by a Leaky ReLU activation function with an alpha value of 0.05 and a max pooling layer to reduce the feature dimensions.\n",
    "        Following the convolutional layers, a Bidirectional Gated Recurrent Unit (BiGRU) layer with 128 hidden units is applied. This layer includes L2 regularization on both kernel and activity weights. The output of the BiGRU layer is flattened and passed through a fully connected Dense layer with 50 hidden units, a Leaky ReLU activation function, and an alpha value of 0.05.\n",
    "        A Dropout layer with a rate of 0.25 is then applied for additional regularization. The final output layer is a Dense layer with a single output unit and a sigmoid activation function, providing the probability for the positive class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model5(embdim=200, emb_dropout=0.2, dropout_rate=0.25, reg=0.01):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(50,)))\n",
    "    model.add(Embedding(15000, embdim, weights=[embedding_matrix]))\n",
    "    model.add(Dropout(emb_dropout))\n",
    "    model.add(Conv1D(16, 3, padding='valid', activation='relu'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(16, 3, padding='valid', activation='relu'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True,\n",
    "                                 kernel_regularizer=regularizers.l2(reg),\n",
    "                                 activity_regularizer=regularizers.l2(reg))))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.05))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = build_model5()\n",
    "evaluate_model(model5, 0.0001, epoch = 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6    \n",
    "        Model 6 is a deep learning architecture employing a stacked Bidirectional Gated Recurrent Unit (BiGRU) structure with three layers, accompanied by dropout regularization and an embedding layer for processing input sequences.\n",
    "        The input sequence is processed through an Embedding layer followed by a SpatialDropout1D layer for regularization. The core of the model comprises three Bidirectional Gated Recurrent Unit (BiGRU) layers with varying hidden units, each followed by a SpatialDropout1D layer for further regularization. The BiGRU layers have L1 and L2 regularization applied to both the kernel and recurrent weights.\n",
    "        After the final BiGRU layer, a GlobalMaxPooling1D layer is used to reduce the feature dimensions, followed by a fully connected Dense layer with a ReLU activation function and a Dropout layer for additional regularization.\n",
    "        The output layer is a Dense layer with a single output unit and a sigmoid activation function, providing the probability for the positive class. The model is compiled using the RMSprop optimizer with a learning rate of 0.0001 and the binary cross-entropy loss function. Performance is evaluated using several metrics, including binary accuracy, AUC, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model6(embdim=200, emb_dropout=0.2, dropout_rate=0.3, reg=0.0001):\n",
    "    i = layers.Input(shape=(50,))\n",
    "    x = layers.Embedding(15000, embdim, weights=[embedding_matrix])(i)\n",
    "    x = layers.SpatialDropout1D(emb_dropout)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.GRU(256, return_sequences=True,\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l1_l2(l1=reg, l2=reg),\n",
    "                                         recurrent_regularizer=tf.keras.regularizers.l1_l2(l1=reg, l2=reg)))(x)\n",
    "    x = layers.SpatialDropout1D(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.GRU(128, return_sequences=True,\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l1_l2(l1=reg, l2=reg),\n",
    "                                         recurrent_regularizer=tf.keras.regularizers.l1_l2(l1=reg, l2=reg)))(x)\n",
    "    x = layers.SpatialDropout1D(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.GRU(64, return_sequences=True,\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l1_l2(l1=reg, l2=reg),\n",
    "                                         recurrent_regularizer=tf.keras.regularizers.l1_l2(l1=reg, l2=reg)))(x)\n",
    "    x = layers.SpatialDropout1D(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs=i, outputs=x)\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[metrics.BinaryAccuracy(name='accuracy'),\n",
    "                           metrics.AUC(name='auc'),\n",
    "                           metrics.Precision(name='precision'),\n",
    "                           metrics.Recall(name='recall'),\n",
    "                           ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = build_model6(embdim=200, emb_dropout=0.3, dropout_rate=0.3, reg=0.001)\n",
    "evaluate_model(model6, 0.001, epoch = 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction \n",
    "\n",
    "        Model 2, model 5 and model 6 are going to be used in the prediction of test twitts. The 2 firsts are more stable and had a good validation F1 score, the last one was better but the trainning was unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"oov\", num_words=18000)\n",
    "tokenizer.fit_on_texts(test[\"text\"])\n",
    "\n",
    "test['text'].values\n",
    "test['token'] = test['text'].apply(tokenize)\n",
    "\n",
    "test_text = test['token']\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=50, padding='post', truncating='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use 'test_padded' for predictions\n",
    "y_pred = model2.predict(test_padded)\n",
    "model_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "model_submission['target'] = np.round(y_pred).astype('int')\n",
    "model_submission.to_csv('model_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use 'test_padded' for predictions\n",
    "y_pred = model5.predict(test_padded)\n",
    "model_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "model_submission['target'] = np.round(y_pred).astype('int')\n",
    "model_submission.to_csv('model_submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use 'test_padded' for predictions\n",
    "y_pred = model6.predict(test_padded)\n",
    "model_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "model_submission['target'] = np.round(y_pred).astype('int')\n",
    "model_submission.to_csv('model_submission6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
